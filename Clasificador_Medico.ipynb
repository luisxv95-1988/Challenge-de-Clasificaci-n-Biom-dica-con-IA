{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOqPZwqgbt6MDSi7vKnBJ4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisxv95-1988/Challenge-de-Clasificaci-n-Biom-dica-con-IA/blob/main/Clasificador_Medico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge de Clasificación Biomédica con IA\n",
        "\n",
        "Crea una solución de IA que ayude a clasificar investigación médica. Perfecto para desarrollar habilidades avanzadas en Data Science y destacar en tu portafolio profesional.\n"
      ],
      "metadata": {
        "id": "gwStmltDDTd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Reconocimiento de datos y EDA.\n",
        "\n",
        "Iniciamos con el reconocimiento de los datos para aprendizaje del modelo a implementar.\n",
        "\n",
        "Verificaremos la cantidad de datos, la integralidad de la información, los grupos.\n",
        "\n",
        "Usaremos la biblioteca Pandas para la manipulación de los datos con Python.\n",
        "\n",
        "Siempre que se ejecute el codigo debemos cargar el archivo de entrenamiento que vamos a utilizar. En este caso 'challenge_data-18-ago.csv'."
      ],
      "metadata": {
        "id": "u0kcwIbEDwRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6eLUSZCDOJ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Obtiene el nombre del archivo cargado\n",
        "file_name1 = next(iter(uploaded))\n",
        "\n",
        "# Asegúrate de que la ruta del archivo sea la correcta en tu Google Drive\n",
        "df = pd.read_csv(file_name1, delimiter=';')\n",
        "\n",
        "# Mostramos las primeras filas para verificar que se cargó correctamente\n",
        "print(\"Primeras 3 filas del DataFrame:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# Verificamos la información general del DataFrame\n",
        "print(\"\\nInformación del DataFrame:\")\n",
        "df.info()\n",
        "\n",
        "# Verificamos si hay valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Contar la frecuencia de cada grupo\n",
        "all_groups = df['group'].str.split('|').explode()\n",
        "group_counts = all_groups.value_counts()\n",
        "\n",
        "print(\"\\nFrecuencia de cada grupo:\")\n",
        "print(group_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de la distribución de los grupos\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.barplot(x=group_counts.index, y=group_counts.values, palette='viridis')\n",
        "plt.title('Distribución de los Grupos Médicos')\n",
        "plt.xlabel('Dominio Médico')\n",
        "plt.ylabel('Número de Artículos')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Añadir etiquetas de datos\n",
        "for p in ax.patches:\n",
        "    ax.text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "            f'{int(p.get_height())}',\n",
        "            fontsize=12, ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verificamos si hay artículos sin grupo asignado\n",
        "empty_group_count = df['group'].isnull().sum()\n",
        "\n",
        "print(f\"\\nNúmero de filas sin grupo asignado: {empty_group_count}\")"
      ],
      "metadata": {
        "id": "vxUivsalGn5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Conclusiones EDA:\n",
        "\n",
        "Análisis de la distribución de etiquetas nos dio la frecuencia de cada grupo.\n",
        "\n",
        "Vamos a analizar esos resultados y a crear una representación visual para entender mejor el problema.\n",
        "\n",
        "Resultados del df.info():\n",
        "\n",
        "El dataset tiene 3565 filas.\n",
        "\n",
        "No hay valores nulos en ninguna de las columnas (title, abstract, group), lo que es excelente y simplifica el preprocesamiento.\n",
        "\n",
        "Todas las columnas son de tipo object (texto), como se esperaba.\n",
        "\n",
        "Resultados de all_groups.value_counts(): Aquí están las frecuencias de cada dominio médico.\n",
        "Frecuencia de cada grupo:\n",
        "neurological      1785\n",
        "cardiovascular    1268\n",
        "hepatorenal       1091\n",
        "oncological        601\n",
        "\n",
        "Reflexiones:\n",
        "\n",
        "Desequilibrio de Clases: Hay un claro desequilibrio. cardiovascular y neurologico son las clases más frecuentes, mientras que oncologico es la menos frecuente con 601 lineas. Este desequilibrio podría afectar el rendimiento del modelo en las clases minoritarias.\n",
        "\n",
        "Clasificación Multi-etiqueta: El hecho de que un artículo pueda tener múltiples etiquetas (| en la columna group) significa que no podemos usar un clasificador simple de una sola clase. Tendremos que transformar esta columna en un formato adecuado para el entrenamiento. La técnica más común es la binarización de etiquetas que es la que aplicaremos a continuación."
      ],
      "metadata": {
        "id": "YW0Gi0-lJrBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preprocesamiento de Datos y Binarización de Etiquetas.\n",
        "\n",
        "Antes de alimentar los datos a un modelo de machine learning, necesitamos prepararlos. Esto incluye la binarización de la columna group y la preparación del texto.\n",
        "\n",
        "Aqui importamos la biblitecas de Numply y sklearn.\n",
        "\n",
        "**Combinación de Texto:** Para simplificar, unimos el title y el abstract en una sola columna llamada text. Esto asegura que toda la información textual esté disponible para el modelo en una sola \"característica\".\n",
        "\n",
        "**Binarización:** La clase MultiLabelBinarizer de scikit-learn es perfecta para este trabajo.\n",
        "\n",
        "**df['group'].apply(lambda x: x.split('|'))** divide la cadena de grupos en una lista de etiquetas.\n",
        "\n",
        "**mlb.fit_transform()** crea una matriz donde cada fila corresponde a un artículo y cada columna a un dominio médico. Un 1 indica que el artículo pertenece a ese dominio, y un 0 indica que no. Esta matriz y será nuestra variable objetivo para el entrenamiento."
      ],
      "metadata": {
        "id": "5B-IhubiKe5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Unimos las columnas 'title' y 'abstract' en una sola\n",
        "df['text'] = df['title'] + ' ' + df['abstract']\n",
        "\n",
        "# Binarizamos la columna 'group'\n",
        "# Primero, separamos las etiquetas\n",
        "df['groups_list'] = df['group'].apply(lambda x: x.split('|'))\n",
        "\n",
        "# Creamos una instancia de MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Ajustamos y transformamos los datos para crear la matriz de etiquetas\n",
        "y = mlb.fit_transform(df['groups_list'])\n",
        "y_df = pd.DataFrame(y, columns=mlb.classes_)\n",
        "\n",
        "# Mostramos las primeras 3 filas de la matriz de etiquetas\n",
        "print(\"\\nPrimeras 3 filas de la matriz de etiquetas binarizadas:\")\n",
        "print(y_df.head(3))\n",
        "print(\"\\nClases detectadas:\")\n",
        "print(list(mlb.classes_))"
      ],
      "metadata": {
        "id": "iaLQBNteLrDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Vectorización del Texto con TF-IDF.\n",
        "\n",
        "TF-IDF no solo cuenta la frecuencia de una palabra en un documento (Term Frequency), sino que también penaliza las palabras que son muy comunes en todo el corpus (Inverse Document Frequency), como \"el\", \"la\", \"un\" ó (como \"the\", \"a\", \"is\" en Ingles como este caso). Esto significa que las palabras que son únicas o más relevantes para un dominio médico específico (por ejemplo, \"cardiaco\" en un texto de cardiología) tendrán un peso mayor en la representación vectorial, lo que hace que los datos sean más significativos para el modelo.\n",
        "\n",
        "Implementación en Python Usaremos TfidfVectorizer de scikit-learn para este paso. También es fundamental dividir los datos en conjuntos de entrenamiento y prueba para poder evaluar el rendimiento del modelo en datos que nunca ha visto.\n",
        "\n",
        "**Cargamos las bibliotecas siguientes bibliotecas de sklearn**\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Aqui parametrizamos el set de datos de la siguiente manera: 80% para entrenamiento y 20% para pruebas. (test_size: 0.2)\n",
        "\n",
        "Se asigna random_state=40 para garantizar la repetibilidad de las pruebas.\n",
        "\n"
      ],
      "metadata": {
        "id": "GTpH3KACMDqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X = df['text']  # Características (texto)\n",
        "y = y_df        # Etiquetas binarizadas\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)\n",
        "\n",
        "print(\"Dimensiones de los conjuntos de datos:\")\n",
        "print(f\"Conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
        "print(f\"Conjunto de prueba (X_test): {X_test.shape}\")\n",
        "print(f\"Etiquetas de entrenamiento (y_train): {y_train.shape}\")\n",
        "print(f\"Etiquetas de prueba (y_test): {y_test.shape}\")\n",
        "\n",
        "# Creamos una instancia de TfidfVectorizer\n",
        "# Podríamos ajustar el max_df, min_df o ngram_range para una mayor optimización\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Ajustamos el vectorizador solo en el conjunto de entrenamiento y lo transformamos\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Usamos el mismo vectorizador para transformar el conjunto de prueba\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nDimensiones de los datos vectorizados:\")\n",
        "print(f\"Matriz de entrenamiento TF-IDF: {X_train_vec.shape}\")\n",
        "print(f\"Matriz de prueba TF-IDF: {X_test_vec.shape}\")"
      ],
      "metadata": {
        "id": "NKb2iLtfNCBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Entrenamiento del Modelo\n",
        "\n",
        "Ahora que nuestros datos están vectorizados y listos, vamos a entrenar el modelo en el conjunto de entrenamiento (X_train_vec, y_train) y luego a evaluarlo en el conjunto de prueba (X_test_vec, y_test).\n",
        "\n",
        "El OneVsRestClassifier funciona creando un clasificador binario para cada una de las clases. Por ejemplo, un clasificador para cardiovascular (que distingue entre cardiovascular y \"no cardiovascular\"), otro para oncological, y así sucesivamente."
      ],
      "metadata": {
        "id": "kPbW9WXKQ2vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Creamos una instancia de OneVsRestClassifier con un modelo base de LogisticRegression\n",
        "# Usamos un solver 'lbfgs' que es eficiente y el C (inverso de la regularización) para controlar el sobreajuste.\n",
        "\n",
        "model = OneVsRestClassifier(LogisticRegression(solver='lbfgs', C=1.1))\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento\n",
        "print(\"Entrenando el modelo...\")\n",
        "model.fit(X_train_vec, y_train)\n",
        "print(\"¡Entrenamiento completado!\")\n",
        "\n",
        "# Hacemos las predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test_vec)\n"
      ],
      "metadata": {
        "id": "bz56B8NfQ2a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b16e052"
      },
      "source": [
        "## 4.1 Entrenar otros dos modelos de clasificación\n",
        "\n",
        "Entrenar otro modelo de clasificación adecuado para problemas multi-etiqueta y entrénalo con los datos vectorizados.\n",
        "\n",
        "En este caso se entrenaron los modelos 'LinearSVC' y 'DecisionTreeClassifier' con el objetivo de evaluar las métricas de F1-Score y elegir el modelo mas ajustado en predicciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06ace6fb"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Create an instance of OneVsRestClassifier with DecisionTreeClassifier as the base estimator\n",
        "# We'll use a random_state for reproducibility\n",
        "model_tree = OneVsRestClassifier(DecisionTreeClassifier(random_state=40))\n",
        "\n",
        "# Train the new model with the vectorized training data\n",
        "print(\"Entrenando el modelo DecisionTreeClassifier...\")\n",
        "# Assuming X_train_vec and y_train are available from previous steps (TF-IDF vectorization)\n",
        "model_tree.fit(X_train_vec, y_train)\n",
        "print(\"¡Entrenamiento de DecisionTreeClassifier completado!\")\n",
        "\n",
        "# Create an instance of OneVsRestClassifier with LinearSVC as the base estimator\n",
        "model_lsvc = OneVsRestClassifier(LinearSVC(C=3.2, random_state=40, dual=True))\n",
        "# Train the new model with the vectorized training data\n",
        "print(\"Entrenando el modelo LinearSVC...\")\n",
        "model_lsvc.fit(X_train_vec, y_train)\n",
        "print(\"¡Entrenamiento de LinearSVC completado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ea00b2e"
      },
      "source": [
        "## 5. Evaluamos los Modelos Preentrenados\n",
        "\n",
        "### Metódo\n",
        "\n",
        "Evaluar los modelos (el actual de Regresión Logística, LinearSVC y Arból de desición) calculando el F1-score ponderado en el conjunto de prueba.\n",
        "\n",
        "En este caso solo continuaremos con el modelo que tenga el mayor F1-Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fea86b2e"
      },
      "source": [
        "# Calculate weighted F1-score for Logistic Regression model\n",
        "f1_weighted_lr = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Make predictions using the LinearSVC model\n",
        "y_pred_lsvc = model_lsvc.predict(X_test_vec)\n",
        "\n",
        "# Calculate weighted F1-score for LinearSVC model\n",
        "f1_weighted_lsvc = f1_score(y_test, y_pred_lsvc, average='weighted')\n",
        "\n",
        "# Make predictions using the DecisionTreeClassifier model\n",
        "y_pred_tree = model_tree.predict(X_test_vec)\n",
        "\n",
        "# Calculate weighted F1-score for DecisionTreeClassifier model\n",
        "# Assuming y_test is available from previous steps (train-test split)\n",
        "f1_weighted_tree = f1_score(y_test, y_pred_tree, average='weighted')\n",
        "\n",
        "print(f\"F1-score ponderado (Regresión Logística): {f1_weighted_lr:.4f}\")\n",
        "print(f\"F1-score ponderado (LinearSVC): {f1_weighted_lsvc:.4f}\")\n",
        "print(f\"F1-score ponderado (Arból de Desición): {f1_weighted_tree:.4f}\")\n",
        "\n",
        "best_f1 = max(f1_weighted_lr, f1_weighted_lsvc, f1_weighted_tree)\n",
        "\n",
        "if best_f1 == f1_weighted_lr:\n",
        "    best_model_name = \"Regresión Logística\"\n",
        "elif best_f1 == f1_weighted_lsvc:\n",
        "    best_model_name = \"LinearSVC\"\n",
        "else:\n",
        "    best_model_name = \"Arból de Desición\"\n",
        "\n",
        "print(f\"\\nEl modelo con el mejor F1-score ponderado es: {best_model_name} ({best_f1:.4f})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluación de Métricas\n",
        "\n",
        "Teniendo en cuenta los resultados del F1-score se selecciona el modelo de LinearSVC para el desarrollo del modelo final.\n",
        "\n",
        "F1-score ponderado (Regresión Logística): 0.8228 F1-score ponderado (LinearSVC): 0.8876 F1-score ponderado (Árbol de Decisión): 0.8476\n",
        "\n",
        "El modelo con el mejor F1-score ponderado es: LinearSVC (0.8876)\n",
        "\n",
        "Se ejecutan todas las métricas para el modelo seleccionado LinearSVR.\n",
        "\n",
        "El reto pide dos métricas clave: el F1-score ponderado y la matriz de confusión.\n",
        "\n",
        "El F1-score ponderado es la métrica principal. Combina la precisión (precision) y la exhaustividad (recall) en una sola métrica y la \"pondera\" (promedia) según el número de ejemplos de cada clase. Esto es crucial en nuestro caso debido al desequilibrio de clases. Un F1-score alto indica un buen balance entre ambas métricas.\n",
        "\n",
        "La matriz de confusión nos dará una visión detallada del rendimiento del modelo para cada clase, mostrando cuántas predicciones fueron correctas (True Positives, True Negatives) e incorrectas (False Positives, False Negatives)."
      ],
      "metadata": {
        "id": "SSekD4G9VfiW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "806ba781"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the classification report for the LinearSVC model\n",
        "print(\"Informe de Clasificación para el Modelo LinearSVC:\")\n",
        "# Ensure target_names are correctly aligned with the columns of y_test\n",
        "print(classification_report(y_test, y_pred_lsvc, target_names=mlb.classes_))\n",
        "\n",
        "# Generate and display the confusion matrix for each class\n",
        "print(\"\\nMatrices de Confusión para cada Clase (LinearSVC):\")\n",
        "\n",
        "# Get the class names from the MultiLabelBinarizer\n",
        "class_names = mlb.classes_\n",
        "\n",
        "# Iterate through each class and calculate/display the confusion matrix\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"\\n--- Matriz de Confusión para '{class_name}' ---\")\n",
        "# Obtener la matriz de confusión para la clase ''{class_name}''\n",
        "    class_index = list(y_df.columns).index(class_name)\n",
        "    cm = confusion_matrix(y_test.iloc[:, class_index], y_pred_lsvc[:, class_index])\n",
        "    # Visualizar la matriz de confusión\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No ', 'Si'], yticklabels=['No ', 'Si '])\n",
        "    plt.title(f'Matriz de Confusión para \"{class_name}\"')\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # Get the true labels and predicted labels for the current class\n",
        "  #  y_true_class = y_test.iloc[:, i]\n",
        "  #  y_pred_class = y_pred_lsvc[:, i]\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    # The matrix will be:\n",
        "    # [[True Negatives (TN), False Positives (FP)]\n",
        "    #  [False Negatives (FN), True Positives (TP)]]\n",
        "   # cm = confusion_matrix(y_true_class, y_pred_class)\n",
        "\n",
        " #   print(cm)\n",
        "\n",
        "    # You can also print TN, FP, FN, TP for clarity\n",
        "  #  tn, fp, fn, tp = cm.ravel()\n",
        " #   print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Cargue de Archivo Prueba\n",
        "\n",
        "En este código el usuario puede cargar los datos etiquetados o no para realizar su respectiva clasificación automática de la investigación médica, cuando los datos están etiquetados el código genera las estadísticas F1-score y Matriz de confusión.\n",
        "\n",
        "El usuario debe iniciar la ejecución del código y el asistente de datos le solicitara adjuntar el archivo."
      ],
      "metadata": {
        "id": "Pdhww_IAPlHy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65e5776f"
      },
      "source": [
        "from google.colab import files\n",
        "import sys\n",
        "\n",
        "# Prompt the user to upload a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the name of the uploaded file\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# Read the uploaded CSV file into a pandas DataFrame\n",
        "df_new = pd.read_csv(file_name, delimiter=';')\n",
        "\n",
        "# Display the first few rows of the new DataFrame to verify\n",
        "print(\"Primeras 3 filas del nuevo DataFrame:\")\n",
        "print(df_new.head(3))\n",
        "\n",
        "# Verify the general information of the new DataFrame\n",
        "print(\"\\nInformación del nuevo DataFrame:\")\n",
        "df_new.info()\n",
        "\n",
        "# Combine the 'title' and 'abstract' columns into a new 'text' column\n",
        "df_new['text'] = df_new['title'] + ' ' + df_new['abstract']\n",
        "\n",
        "# Display the first few rows of the new DataFrame with the added 'text' column\n",
        "print(\"Primeras 3 filas del nuevo DataFrame con la columna 'text':\")\n",
        "print(df_new.head(3))\n",
        "\n",
        "# Transform the 'text' column of the new DataFrame using the fitted vectorizer\n",
        "X_new_vec = vectorizer.transform(df_new['text'])\n",
        "\n",
        "# Print the dimensions of the new TF-IDF matrix\n",
        "print(\"\\nDimensiones de la nueva matriz TF-IDF:\")\n",
        "print(X_new_vec.shape)\n",
        "\n",
        "# Make predictions using the trained LinearSVC model (model_lsvc)\n",
        "y_new_pred = model_lsvc.predict(X_new_vec)\n",
        "\n",
        "# Print the shape of the predictions\n",
        "print(\"\\nDimensiones de las predicciones para el nuevo DataFrame:\")\n",
        "print(y_new_pred.shape)\n",
        "\n",
        "# Convert the predicted labels (binary matrix) back to class names\n",
        "predicted_groups = mlb.inverse_transform(y_new_pred)\n",
        "\n",
        "# Join the predicted groups (lists of strings) into a single string separated by '|'\n",
        "predicted_groups_str = ['|'.join(groups) for groups in predicted_groups]\n",
        "\n",
        "# Add the predicted groups as a new column 'group_predicted' to the original new DataFrame\n",
        "df_new['group_predicted'] = predicted_groups_str\n",
        "\n",
        "# Display the first few rows of the DataFrame with the new 'group_predicted' column\n",
        "print(\"\\nPrimeras 3 filas del DataFrame con la columna 'group_predicted':\")\n",
        "print(df_new.head(3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fc8806"
      },
      "source": [
        "# 7.1 Verifica datos de Clasificación\n",
        "\n",
        "Verificar si el DataFrame original contiene una columna 'group' para determinar si se pueden calcular métricas de evaluación, luego imprimir un mensaje indicando el resultado.\n",
        "\n",
        "Si no se ejecuta no se muestran los resultados de las pruebas de clasificación por F1-Score y por Matriz de Confusión para cada grupo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d51f68f9"
      },
      "source": [
        "# Check if the original 'group' column exists in the new DataFrame\n",
        "if 'group' in df_new.columns:\n",
        "    print(\"\\nEl archivo cargado contiene la columna 'group'. Procederemos a calcular métricas de evaluación.\")\n",
        "    calculate_metrics = True\n",
        "else:\n",
        "    print(\"\\nEl archivo cargado NO contiene la columna 'group'. No se calcularán métricas de evaluación.\")\n",
        "    calculate_metrics = False\n",
        "\n",
        "\n",
        "# If the 'group' column exists, calculate and display evaluation metrics\n",
        "if calculate_metrics:\n",
        "    # Create the 'groups_list' column in the new DataFrame by splitting the 'group' column\n",
        "    df_new['groups_list'] = df_new['group'].apply(lambda x: x.split('|'))\n",
        "\n",
        "    # Binarize the actual 'group' column from the new DataFrame\n",
        "    # Ensure mlb is fitted with all possible classes from the original training data\n",
        "    y_new_actual = mlb.transform(df_new['groups_list'])\n",
        "\n",
        "    # Generate the classification report for the LinearSVC model\n",
        "    print(\"\\nInforme de Clasificación para el Modelo LinearSVC en el nuevo archivo:\")\n",
        "    print(classification_report(y_new_actual, y_new_pred, target_names=mlb.classes_))\n",
        "\n",
        "    # Generate and display the confusion matrix for each class\n",
        "    print(\"\\nMatrices de Confusión para cada Clase (LinearSVC) en el nuevo archivo:\")\n",
        "\n",
        "    # Get the class names from the MultiLabelBinarizer\n",
        "    class_names = mlb.classes_\n",
        "\n",
        "    # Iterate through each class and calculate/display the confusion matrix\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"\\n--- Matriz de Confusión para '{class_name}' ---\")\n",
        "\n",
        "        # Get the true labels and predicted labels for the current class\n",
        "        y_true_class = y_new_actual[:, i]\n",
        "        y_pred_class = y_new_pred[:, i]\n",
        "\n",
        "        # Calculate the confusion matrix\n",
        "        cm = confusion_matrix(y_true_class, y_pred_class)\n",
        "\n",
        "        # Visualizar la matriz de confusión\n",
        "        plt.figure(figsize=(2, 2))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No ', 'Si'], yticklabels=['No ', 'Si '])\n",
        "        plt.title(f'Matriz de Confusión para \"{class_name}\"')\n",
        "        plt.xlabel('Predicho')\n",
        "        plt.ylabel('Real')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dab739d"
      },
      "source": [
        "# 7.2 Mostrar y Guardar los Resultados.\n",
        "\n",
        "Mostrar las primeras 10 filas del DataFrame con las predicciones y guardar el DataFrame actualizado en un archivo nuevo llamado 'predictions_values.CSV' el cual sera descargado por el navegador a la carpeta de descargas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "066d2954"
      },
      "source": [
        "from google.colab import files\n",
        "# Drop the 'text' column as requested\n",
        "if 'text' in df_new.columns:\n",
        "    df_new = df_new.drop(columns=['text'])\n",
        "if 'groups_list' in df_new.columns:\n",
        "    df_new = df_new.drop(columns=['groups_list'])\n",
        "# Display the first 10 rows of the DataFrame with the new 'group_predicted' column\n",
        "print(\"\\nPrimeras 10 filas del DataFrame con la columna 'group_predicted':\")\n",
        "display(df_new.head(10))\n",
        "\n",
        "# (Optional) Save the updated DataFrame to a new CSV file\n",
        "df_new.to_csv('predictions_values.csv', index=False)\n",
        "print(\"\\nDataFrame actualizado guardado en 'predictions_values.csv'\")\n",
        "try:\n",
        "  files.download('predictions_values.csv')\n",
        "  print(\"\\nVer archivo en la carpeta de 'Descargas' de tu computador\")\n",
        "except:\n",
        "  print(\"\\nNo se pudo descargar el archivo al computador\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "832301d5"
      },
      "source": [
        "# Resumen:\n",
        "\n",
        "## Hallazgos Clave del Análisis de Datos\n",
        "\n",
        "* El sistema cargó exitosamente un archivo CSV proporcionado por el usuario en un DataFrame de pandas, verificando su estructura y contenido.\n",
        "* Se creó una nueva columna 'text' combinando las columnas 'title' y 'abstract' de los datos de entrada, para ayudar a la vectorización.\n",
        "* El `TfidfVectorizer` previamente entrenado transformó exitosamente la columna 'text' en una matriz TF-IDF con dimensiones (3565, 5000).\n",
        "* El modelo `LinearSVC` entrenado generó predicciones multi-etiqueta para las 3565 entradas, resultando en un array de predicción de forma (3565, 4).\n",
        "* Las etiquetas binarias predichas se convirtieron de nuevo a nombres de grupo y se añadieron como una nueva columna 'group_predicted' al DataFrame.\n",
        "* Cuando el archivo de entrada contenía una columna 'group' original, se calcularon y mostraron métricas de evaluación, incluyendo un informe de clasificación y matrices de confusión para cada clase, mostrando el rendimiento del modelo en los nuevos datos.\n",
        "* Se mostraron las primeras 10 filas del DataFrame actualizado, incluyendo la columna 'group_predicted'.\n",
        "\n",
        "### Insights\n",
        "\n",
        "* El proceso integró exitosamente un modelo y vectorizador pre-entrenados para hacer predicciones en datos nuevos y no vistos proporcionados por el usuario, cumpliendo el requisito principal de la tarea.\n",
        "* Se evaluaron otros modelos como redes neuronales con tensorflow.Keras, sin embargo, no se tuvieron resultados satisfactorios en las pruebas realizadas pre-eliminarmente y los tiempos de entrenamiento y respuesta de maquina eran mucho mayores a los observados con sklearn.\n",
        "* Se lograron valores para el F1-score del 0.98 con el data set original, solo el subgrupo oncological tiene un menor valor, debido a que fue el grupo con menor cantidad de datos en el DataSet de entrenamiento para el modelo, sin embargo llego al 0.98.\n",
        "* Se implemeta el paso de guardar el DataFrame actualizado en un nuevo archivo CSV (`predictions_values.csv`) para proporcionar un archivo de salida fácilmente utilizable para el usuario."
      ]
    }
  ]
}